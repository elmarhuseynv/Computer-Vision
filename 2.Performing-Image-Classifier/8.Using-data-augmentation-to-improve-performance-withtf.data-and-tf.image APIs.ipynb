{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(width, height, depth, classes):\n",
    "    input_layer = Input(shape=(width, height, depth))\n",
    "\n",
    "    x = Conv2D(filters=32,\n",
    "               kernel_size=(3,3),\n",
    "               padding='same')(input_layer)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(filters=32,\n",
    "               kernel_size=(3,3),\n",
    "               padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(rate=0.25)(x)\\\n",
    "    \n",
    "    x = Conv2D(filters=64,\n",
    "               kernel_size=(3,3),\n",
    "               padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(filters=64,\n",
    "               kernel_size=(3,3),\n",
    "               padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(rate=0.25)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=512)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "\n",
    "    x = Dense(units=classes)(x)\n",
    "    output = Softmax()(x)\n",
    "\n",
    "    return Model(input_layer, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, metric, plot_name):\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    plotter = tfdocs.plots.HistoryPlotter()\n",
    "    plotter.plot({'Model': model_history}, metric=metric)\n",
    "    plt.title(f'{metric.upper()}')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.savefig(f'{plot_name}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_and_label(image_path, target_size=(64,64)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, np.float32)\n",
    "    image = tf.image.resize(image, target_size)\n",
    "\n",
    "    label = tf.strings.split(image_path, os.path.sep)[-2]\n",
    "    label = (label == CLASSES)\n",
    "    label = tf.dtypes.cast(label, tf.float32)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, label):\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 74, 74)\n",
    "    image = tf.image.random_srop(image, size=(64,64,3))\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, 0.2)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data_pattern):\n",
    "    return (tf.data.Dataset\n",
    "            .from_tensor_slices(data_pattern)\n",
    "            .map(load_image_and_label,\n",
    "                 num_parallel_calls=AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 999\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = ('C:/Users/hp/Documents/DATA/caltech-101/101_ObjectCategories/*/*.jpg')\n",
    "image_pattern = str(base_path)\n",
    "image_paths = [*glob.glob(image_pattern)]\n",
    "image_paths = [p for p in image_paths if\n",
    "               p.split(os.path.sep)[-2] !=\n",
    "               'BACKGROUND_Google']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = np.unique([p.split(os.path.sep)[-2]\n",
    "                     for p in image_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, test_paths = train_test_split(image_paths, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1024\n",
    "train_dataset = (prepare_dataset(train_paths)\n",
    "                 .batch(BATCH_SIZE)\n",
    "                 .shuffle(buffer_size=BUFFER_SIZE)\n",
    "                 .prefetch(buffer_size=BUFFER_SIZE))\n",
    "test_dataset = (prepare_dataset(test_paths)\n",
    "                .batch(BATCH_SIZE)\n",
    "                .prefetch(buffer_size=BUFFER_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model = build_network(64, 64, 3, len(CLASSES))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics = ['accuracy'])\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=test_dataset,\n",
    "                    epochs=EPOCHS)\n",
    "result = model.evaluate(test_dataset)\n",
    "print(f\"test accuracy: {result[1]}\")\n",
    "plot_model_history(history, 'accuracy', 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
