{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "TRAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_module(data,\n",
    "                     filters,\n",
    "                     stride,\n",
    "                     reduce=False,\n",
    "                     reg=0.0001,\n",
    "                     bn_eps=2e-5,\n",
    "                     bn_momentum=0.9):\n",
    "    shortcut = data\n",
    "    bn_1 = BatchNormalization(axis=-1, \n",
    "                              epsilon=bn_eps, \n",
    "                              momentum=bn_momentum)(data)\n",
    "    act_1 = ReLU()(bn_1)\n",
    "    conv_1 = Conv2D(filters=int(filters / 4.),\n",
    "                    kernel_size=(1,1),\n",
    "                    use_bias=False,\n",
    "                    kernel_regularizer=l2(reg))(act_1)\n",
    "    bn_2 = BatchNormalization(axis=-1, \n",
    "                              epsilon=bn_eps, \n",
    "                              momentum=bn_momentum)(conv_1)\n",
    "    act_2 = ReLU()(bn_2)\n",
    "    conv_2 = Conv2D(filters=int(filters / 4.),\n",
    "                    kernel_size=(3,3),\n",
    "                    strides=stride,\n",
    "                    padding='same',\n",
    "                    use_bias=False,\n",
    "                    kernel_regularizer=l2(reg))(act_2)\n",
    "    bn_3 = BatchNormalization(axis=-1,\n",
    "                              epsilon=bn_eps,\n",
    "                              momentum=bn_momentum)(conv_2)\n",
    "    act_3 = ReLU()(bn_3)\n",
    "    conv_3 = Conv2D(filters=filters,\n",
    "                    kernel_size=(1,1),\n",
    "                    use_bias=False,\n",
    "                    kernel_regularizer=l2(reg))(act_3)\n",
    "    if reduce:\n",
    "        shortcut = Conv2D(filters=filters,\n",
    "                          kernel_size=(1,1),\n",
    "                          strides=stride,\n",
    "                          use_bias=False,\n",
    "                          kernel_regularizer=l2(reg))(act_3)\n",
    "    x = Add()([conv_3, shortcut])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_shape,\n",
    "                 classes,\n",
    "                 stages,\n",
    "                 filters,\n",
    "                 reg=1e-3,\n",
    "                 bn_eps=2e-5,\n",
    "                 bn_momentum=0.9):\n",
    "    inputs = Input(shape = input_shape)\n",
    "    x = BatchNormalization(axis=-1,\n",
    "                           epsilon=bn_eps,\n",
    "                           momentum=bn_momentum)(inputs)\n",
    "    x = Conv2D(filters[0], (3,3), \n",
    "               use_bias=False,\n",
    "               padding='same',\n",
    "               kernel_regularizer=l2(reg))(x)\n",
    "    \n",
    "    for i in range(len(stages)):\n",
    "        stride = (1,1) if i == 0 else (2,2)\n",
    "        x = residual_module(data=x,\n",
    "                            filters=filters[i + 1],\n",
    "                            stride=stride,\n",
    "                            reduce=True,\n",
    "                            bn_eps=bn_eps,\n",
    "                            bn_momentum=bn_momentum)\n",
    "        for j in range(stages[i] - 1):\n",
    "            x = residual_module(data=x,\n",
    "                                filters=filters[i + 1],\n",
    "                                stride=(1,1),\n",
    "                                bn_eps=bn_eps,\n",
    "                                bn_momentum=bn_momentum,)\n",
    "    \n",
    "    x = BatchNormalization(axis=-1, \n",
    "                           epsilon=bn_eps,\n",
    "                           momentum=bn_momentum)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = AvaragePooling2D((8,8))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Densen(classes, kernel_regularizer=l2(reg))(x)\n",
    "    x = Softmax()(x)\n",
    "\n",
    "    return Model(inputs, x, name='resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(image_path, target_size=(32,32)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, np.float32)\n",
    "    image -= CINIC_MEAN_RGB\n",
    "    image = tf.image.resize(image, target_size)\n",
    "\n",
    "    label = tf.strings.split(image_path, os.path.sep)[-2]\n",
    "    label = (label == CINIC_10_CLASSES)\n",
    "    label = tf.dtypes.cast(label, tf.float32)\n",
    "\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data_pattern, shuffle=False):\n",
    "    dataset = (tf.data.Dataset\n",
    "               .list_files(data_pattern)\n",
    "               .map(load_images_and_labels,\n",
    "                    num_parallel_calls=AUTOTUNE)\n",
    "                    .batch(BATCH_SIZE))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "    return dataset.prefetch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CINIC_MEAN_RGB = np.array([0.47889522, 0.47227842, 0.43047404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CINIC_10_CLASSES = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = 'https://datashare.is.ed.ac.uk/bitstream/handle/10283/3192/CINIC-10.tar.gz?sequence=4&isAllowed=y'\n",
    "DATA_NAME = 'cinic10'\n",
    "FILE_EXTENSION = 'tar.gz'\n",
    "FILE_NAME = '.'.join([DATA_NAME, FILE_EXTENSION])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_file_location = get_file(origin=DATASET_URL, fname=FILE_NAME, extract=False)\n",
    "\n",
    "data_directory, _ = downloaded_file_location.rsplit(os.path.sep, maxsplit=1)\n",
    "data_directory = os.path.sep.join([data_directory, DATA_NAME])\n",
    "tar = tarfile.open(downloaded_file_location)\n",
    "\n",
    "if not os.path.exists(data_directory):\n",
    "    tar.extractall(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pattern = os.path.sep.join([data_directory, 'train/*/*.png'])\n",
    "test_pattern = os.path.sep.join([data_directory, 'test/*/*.png'])\n",
    "valid_pattern = os.path.sep.join([data_directory, 'valid/*/*.png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 1024\n",
    "\n",
    "train_dataset = prepare_dataset(train_pattern, shuffle=True)\n",
    "test_dataset = prepare_dataset(test_pattern, shuffle=True)\n",
    "valid_dataset = prepare_dataset(valid_pattern, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    model = build_resnet(input_shape=(32, 32, 3),\n",
    "                         classes=10,\n",
    "                         stages=(9, 9, 9),\n",
    "                         filters=(64, 64, 128, 256),\n",
    "                         reg=5e-3)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath='./model.{epoch:02d}-{val_accuracy:.2f}.hdf5',\n",
    "        save_weights_only=False,\n",
    "        monitor='val_accuracy')\n",
    "\n",
    "    EPOCHS = 100\n",
    "    model.fit(train_dataset,\n",
    "              validation_data=valid_dataset,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at model.38-0.72.hdf5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hp\\Documents\\GitHub\\Computer-Vision\\2.Performing-Image-Classifier\\4.Implementing-ResNet-from-scratch.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hp/Documents/GitHub/Computer-Vision/2.Performing-Image-Classifier/4.Implementing-ResNet-from-scratch.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39;49m\u001b[39mmodel.38-0.72.hdf5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hp/Documents/GitHub/Computer-Vision/2.Performing-Image-Classifier/4.Implementing-ResNet-from-scratch.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_dataset)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hp/Documents/GitHub/Computer-Vision/2.Performing-Image-Classifier/4.Implementing-ResNet-from-scratch.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest accuracy: \u001b[39m\u001b[39m{\u001b[39;00mresult[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\saving\\save.py:226\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 226\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    231\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[0;32m    232\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[0;32m    233\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at model.38-0.72.hdf5"
     ]
    }
   ],
   "source": [
    "model = load_model('model.38-0.72.hdf5')\n",
    "result = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
