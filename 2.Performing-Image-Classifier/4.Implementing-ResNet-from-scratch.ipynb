{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "TRAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_module(data,\n",
    "                     filters,\n",
    "                     stride,\n",
    "                     reduce=False,\n",
    "                     reg=0.0001,\n",
    "                     bn_eps=2e-5,\n",
    "                     bn_momentum=0.9):\n",
    "    shortcut = data\n",
    "    bn_1 = BatchNormalization(axis=-1, \n",
    "                              epsilon=bn_eps, \n",
    "                              momentum=bn_momentum)(data)\n",
    "    act_1 = ReLU()(bn_1)\n",
    "    conv_1 = Conv2D(filters=int(filters / 4.),\n",
    "                    kernel_size=(1,1),\n",
    "                    use_bias=False,\n",
    "                    kernel_regularizer=l2(reg))(act_1)\n",
    "    bn_2 = BatchNormalization(axis=-1, \n",
    "                              epsilon=bn_eps, \n",
    "                              momentum=bn_momentum)(conv_1)\n",
    "    act_2 = ReLU()(bn_2)\n",
    "    conv_2 = Conv2D(filters=int(filters / 4.),\n",
    "                    kernel_size=(3,3),\n",
    "                    strides=stride,\n",
    "                    padding='same',\n",
    "                    use_bias=False,\n",
    "                    kernel_regularizer=l2(reg))(act_2)\n",
    "    bn_3 = BatchNormalization(axis=-1,\n",
    "                              epsilon=bn_eps,\n",
    "                              momentum=bn_momentum)(conv_2)\n",
    "    act_3 = ReLU()(bn_3)\n",
    "    conv_3 = Conv2D(filters=filters,\n",
    "                    kernel_size=(1,1),\n",
    "                    use_bias=False,\n",
    "                    kernel_regularizer=l2(reg))(act_3)\n",
    "    if reduce:\n",
    "        shortcut = Conv2D(filters=filters,\n",
    "                          kernel_size=(1,1),\n",
    "                          strides=stride,\n",
    "                          use_bias=False,\n",
    "                          kernel_regularizer=l2(reg))(act_3)\n",
    "    x = Add()([conv_3, shortcut])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_shape,\n",
    "                 classes,\n",
    "                 stages,\n",
    "                 filters,\n",
    "                 reg=1e-3,\n",
    "                 bn_eps=2e-5,\n",
    "                 bn_momentum=0.9):\n",
    "    inputs = Input(shape = input_shape)\n",
    "    x = BatchNormalization(axis=-1,\n",
    "                           epsilon=bn_eps,\n",
    "                           momentum=bn_momentum)(inputs)\n",
    "    x = Conv2D(filters[0], (3,3), \n",
    "               use_bias=False,\n",
    "               padding='same',\n",
    "               kernel_regularizer=l2(reg))(x)\n",
    "    \n",
    "    for i in range(len(stages)):\n",
    "        stride = (1,1) if i == 0 else (2,2)\n",
    "        x = residual_module(data=x,\n",
    "                            filters=filters[i + 1],\n",
    "                            stride=stride,\n",
    "                            reduce=True,\n",
    "                            bn_eps=bn_eps,\n",
    "                            bn_momentum=bn_momentum)\n",
    "        for j in range(stages[i] - 1):\n",
    "            x = residual_module(data=x,\n",
    "                                filters=filters[i + 1],\n",
    "                                stride=(1,1),\n",
    "                                bn_eps=bn_eps,\n",
    "                                bn_momentum=bn_momentum,)\n",
    "    \n",
    "    x = BatchNormalization(axis=-1, \n",
    "                           epsilon=bn_eps,\n",
    "                           momentum=bn_momentum)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = AvaragePooling2D((8,8))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Densen(classes, kernel_regularizer=l2(reg))(x)\n",
    "    x = Softmax()(x)\n",
    "\n",
    "    return Model(inputs, x, name='resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(image_path, target_size=(32,32)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, np.float32)\n",
    "    image -= CINIC_MEAN_RGB\n",
    "    image = tf.image.resize(image, target_size)\n",
    "\n",
    "    label = tf.strings.split(image_path, os.path.sep)[-2]\n",
    "    label = (label == CINIC_10_CLASSES)\n",
    "    label = tf.dtypes.cast(label, tf.float32)\n",
    "\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data_pattern, shuffle=False):\n",
    "    dataset = (tf.data.Dataset\n",
    "               .list_files(data_pattern)\n",
    "               .map(load_images_and_labels,\n",
    "                    num_parallel_calls=AUTOTUNE)\n",
    "                    .batch(BATCH_SIZE))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "    return dataset.prefetch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CINIC_MEAN_RGB = np.array([0.47889522, 0.47227842, 0.43047404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CINIC_10_CLASSES = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = 'https://datashare.is.ed.ac.uk/bitstream/handle/10283/3192/CINIC-10.tar.gz?sequence=4&isAllowed=y'\n",
    "DATA_NAME = 'cinic10'\n",
    "FILE_EXTENSION = 'tar.gz'\n",
    "FILE_NAME = '.'.join([DATA_NAME, FILE_EXTENSION])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_file_location = get_file(origin=DATASET_URL, fname=FILE_NAME, extract=False)\n",
    "\n",
    "data_directory, _ = downloaded_file_location.rsplit(os.path.sep, maxsplit=1)\n",
    "data_directory = os.path.sep.join([data_directory, DATA_NAME])\n",
    "tar = tarfile.open(downloaded_file_location)\n",
    "\n",
    "if not os.path.exists(data_directory):\n",
    "    tar.extractall(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pattern = os.path.sep.join([data_directory, 'train/*/*.png'])\n",
    "test_pattern = os.path.sep.join([data_directory, 'test/*/*.png'])\n",
    "valid_pattern = os.path.sep.join([data_directory, 'valid/*/*.png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 1024\n",
    "\n",
    "train_dataset = prepare_dataset(train_pattern, shuffle=True)\n",
    "test_dataset = prepare_dataset(test_pattern, shuffle=True)\n",
    "valid_dataset = prepare_dataset(valid_pattern, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    model = build_resnet(input_shape=(32, 32, 3),\n",
    "                         classes=10,\n",
    "                         stages=(9, 9, 9),\n",
    "                         filters=(64, 64, 128, 256),\n",
    "                         reg=5e-3)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath='./model.{epoch:02d}-{val_accuracy:.2f}.hdf5',\n",
    "        save_weights_only=False,\n",
    "        monitor='val_accuracy')\n",
    "\n",
    "    EPOCHS = 100\n",
    "    model.fit(train_dataset,\n",
    "              validation_data=valid_dataset,\n",
    "              epochs=EPOCHS,\n",
    "              callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 700s 958ms/step - loss: 1.4183 - accuracy: 0.7196\n",
      "Test accuracy: 0.7195666432380676\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.38-0.72.hdf5')\n",
    "result = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {result[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
